{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m model_from_json\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      7\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\__init__.py:20\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\distribute\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Keras' Distribution Strategy library.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistribute\u001b[39;00m \u001b[39mimport\u001b[39;00m sidecar_evaluator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\distribute\\sidecar_evaluator.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Python module for evaluation loop.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplatform\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_logging \u001b[39mas\u001b[39;00m logging\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import *\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrbutes = ['mfcc%d'%%i for i in range(1,21)]\n",
    "pd.plotting.scatter_matrix(data[attrbutes], figsize=(12,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrbutes2 = ['choma_stft','rmse','spectral_centroid','spectral_bandwidth','rollff','zero_crossing_rate']\n",
    "pd.plotting.scatter_matrix(data[attrbutes2], figsize=(12,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lebels = data.iloc[:, -1]\n",
    "enconder = preprocessing.LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = enconder.fit_transform(labels)#se obtienen los labels\n",
    "print(y.shape,np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping de columnas inncesarias \n",
    "data = data.drop(['filname'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing,StandardScaler()#se estandarizan las caracteristicas z=(x-u/s)\n",
    "x = scaler.fit_transform(np.array(data.iloc[:,:-1], dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardamos los valores de las medias y desviaciones estandar\n",
    "np.save(\"medias\", scaler.mean_)\n",
    "np.save(\"desvest\", scaler.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_trest, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr(est,x,y):\n",
    "    p= est.predict(x)\n",
    "    return np.mean (p[y==1] == y[y==1])\n",
    "\n",
    "def tnr(est,x,y):\n",
    "    p = est.predict(x)\n",
    "    return np.mean(p[y==0] == y[y==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold\n",
    "from sklearn,metric import *\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "g = GaussianNB()\n",
    "#Xtr, xts, ytr, yts, = train_test_split(x,y, test_size=.2)\n",
    "#rf.fit(xtr,ytr)\n",
    "#g.fit(xtr,ytr)\n",
    "rf.fit(x_train,y_train)\n",
    "g.fit(x_train,y_train)\n",
    "print(\"Randow Forest Accuracy :\",rf.score(x_test,y_test))\n",
    "print(\"Naive Bayes Accuracy :\",g.score(x_test,y_test))\n",
    "print(\"shape :\",x.shape)\n",
    "X2 = PCA(n_components=20).fit_transform(x)\n",
    "print (\"schape after PCA:\", X2.shape)\n",
    "srf = cross_val_score(GaussianNB(), X2, y, cv=KFold(10, shuffle=True),scoring=make_scorer(accuracy_score))\n",
    "print (\"RF accuracy %.3f (+/- %.5f\"%(np.mean(srf), np.std(srf)))\n",
    "s = cross_val_score(GaussianNB(), X2, y, cv=KFold(10, shuffle=True), scoring=make_scorer(accuracy_score))\n",
    "print (\"GNB accuracy %.3f (+/- %.5f)\"%(np.mean(s), np.std(s)))\n",
    "\n",
    "predictions=rf.predict(x_test)\n",
    "rf_model_cm = confusion_matrix(y_test, predictions)\n",
    "rf_model_df_cm = pd.DataFrame(rf_model_cm)\n",
    "plt.figure(figsize = (20,14))\n",
    "sn.heatmap(rf_model_cm, annot=True, annot_kws={\"size\": 12})# front size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "estGNB = GaussianNB()\n",
    "s1GNB = cross_val_score(estGNB, x, y, cv=KFold(10, shuffle=True), scoring=make_scorer(accuracy_score))\n",
    "print(\"accuracy %.3f (+/- %.5f)\"%(np.mean(s1GNB), np.std(s1GNB)))\n",
    "s2GNB = cross_val_score(estGNB, x, y, cv=KFold(10, shuffle=True), scoring=tpr)\n",
    "print(\"tpr     %.3f (+/- %5f)\"%(np.mean(s2GNB), np.std(s2GNB)))\n",
    "s3GNB = cross_val_score(estGNB, x, y, cv=KFold(10, shuffle=True), scoring=tnr)\n",
    "print(\"tnr   %.3f (+/- %.5f)\"%(np.mean(s3GNB), np.std(s3GNB)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "estRFC = RandomForestClassifier(n_estimators = 20)\n",
    "s1RFC = cross_val_score(estGNB, x, y, cv=KFold(10, shuffle=True), scoring=make_scorer(accuracy_score))\n",
    "print(\"accuracy %.3f (+/- %.5f)\"%(np.mean(s1GNB), np.std(s1GNB)))\n",
    "s2RFC = cross_val_score(estRFC, x, y, cv=KFold(10, shuffle=True), scoring=tpr)\n",
    "print(\"tpt   %.3f (+/- %.5f)\"%(np.mean(s2RFC), np.stad(s2RFC)))\n",
    "s3RFC = cross_val_score(estRFC, x, y, cv=KFold(10, shuffle=True), scoring=tnr)\n",
    "print(\"tnr   %.3f (+/- %.5f)\"%(np.mean(s3RFC), np.std(s3RFC)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "estDTC = DecisionTreeClassifier()\n",
    "s1DTC = cross_val_score(estDTC, x, y, cv=KFold(10, shuffle=True), scoring=make_scorer(accuracy_score))\n",
    "print(\"accuracy  %.3f (+/- %.5f\"%(np.mean(s1DTC), np.std(s1DTC)))\n",
    "s2DTC = cross_val_score(estDTC, x, y, cv=KFold(10, shuffle=True), scoring=tpr)\n",
    "print(\"tpr   %.3f  (+/- %.5f\"%(np.mean(s2DTC), np.std(s2DTC)))\n",
    "s3Dtc = cross_val_score(estDTC, X, Y, cv=KFold(10, shuffle=True), scoring=tnr)\n",
    "print(\"tnr  %.3f (+/- %.5f)\"%(np.mean(s3Dtc), np.std(s3Dtc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "estSVC = SVC(gamma='auto')\n",
    "s1SVC = cross_val_score(estSVC, x, y, cv=KFold(10, shuffle=True), scoring=make_scorer(accuracy_score))\n",
    "print(\"accuracy %.3f (+/- %.5f)\"%(np.mean(s1SVC), np.std(s1SVC)))\n",
    "s2SVC = cross_val_score(estSVC, x, y, cv=KFold(10, shuffle=True), scoring=tpr)\n",
    "print(\"tpr   %.3f  (+/- %.5f)\"%(np.mean(s2SVC), np.std(s2SVC)))\n",
    "s3SVC = cross_val_score(estSVC, x, y, cv=KFold(10, shuffle=True), scoring=tnr)\n",
    "print(\"tnr   %.3f (+/- %.5f\"%(np.mean(s3SVC), np.std(s3SVC)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "\n",
    "model.add(layers.Danse(128, activation='rule', input_shape=(x_train.shape[1],)))\n",
    "\n",
    "model.add(layers.Danse(64, activition='rule'))\n",
    "\n",
    "model.add(layers.Dense(10, activition='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compli(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_trest,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test_acc:',test_acc)\n",
    "print('test_loos:',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "model_pred = model.predict(x_test)\n",
    "\n",
    "values_predicted = np.argmax(model_pred,axis=1)\n",
    "model_cm = confusion_matrix(y_test, values_predicted)\n",
    "model_df_cm = pd.DataFrame(model_cm)\n",
    "plt.figure(figsize = (20,14))\n",
    "sn.set(font_scale=1.4) #for label size\n",
    "sn.heatmap(model_df_cm, annot=True, annot_kws={\"size\": 12}) # font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "       json_file.write(model_json)\n",
    "       # serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.clase()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"loaded model from disk\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "#compiling the loaded model\n",
    "loaded_model.compile(optimizer='adam',\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics=\n",
    "               ['accuracy'])\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "print('test_acc: ',test_acc)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  Ipython.display import display, HTML\n",
    "table = [[\"Naive Gaussin Bayes\", np.mean(s1GNB)],\n",
    "          [\"Decision tree Classifeir\",np.mean(s1DTC)],\n",
    "          [\"Random Forest Classifier\",np.mean(s1RFC)],\n",
    "          [\"Support Vector Machine\",np.mean(s1SVC)],\n",
    "          [\"Keras Sequential Model\",test_acc]]\n",
    "compDF = pd.DataFrome(table, columns=[\"Clasificador\",\"Accuracy\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CSS properties for th elements in dataframe\n",
    "th_props = [\n",
    "    ('font-size','40px'),\n",
    "    ('text-align','center'),\n",
    "    ('font-weight','bold'),\n",
    "    ('color','#6d6d6d'),\n",
    "    ('background-color','#f7f7f9')\n",
    "]\n",
    "\n",
    "# set CSS properties for td elements in dataframe\n",
    "td_props = [\n",
    "   ('font-size','30px'),\n",
    "]\n",
    "\n",
    "# set table styles \n",
    "sty_props = [\n",
    "    dict(selector=\"th\", props=th_props),\n",
    "    dict(selector=\"td\", props=td_props)\n",
    "] \n",
    "\n",
    "(compDF.style\n",
    "    .format({'total_amt_usd_pct_diff':\"{:.2$}\"})\n",
    "    .set_table_styles(styles)\n",
    "    .hide_index())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "602bbe8e8fe3127dc2d2bb8f57c49cfbb507be2cc0e090f10eb4c4d0af354b8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
